import streamlit as st
import numpy as np
import cv2
from PIL import Image
from tensorflow.keras.models import load_model
import os

# === Load model ===
@st.cache_resource(show_spinner="ğŸ”„ Äang táº£i mÃ´ hÃ¬nh nháº­n diá»‡n cáº£m xÃºc...")
def load_emotion_model():
    BASE_DIR = os.path.dirname(os.path.abspath(__file__))
    model_path = os.path.join(BASE_DIR, "emotion_model.h5")
    return load_model(model_path)

# === PhÃ¡t hiá»‡n vÃ  cáº¯t khuÃ´n máº·t ===
def detect_and_crop_face(image):
    face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + "haarcascade_frontalface_default.xml")
    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5)

    if len(faces) == 0:
        return None

    # Láº¥y khuÃ´n máº·t lá»›n nháº¥t
    x, y, w, h = sorted(faces, key=lambda f: f[2]*f[3], reverse=True)[0]
    face_img = image[y:y+h, x:x+w]
    return face_img

# === Dá»± Ä‘oÃ¡n cáº£m xÃºc ===
def predict_emotion(image_bgr, model):
    face = detect_and_crop_face(image_bgr)
    if face is None:
        return "KhÃ´ng tÃ¬m tháº¥y khuÃ´n máº·t", 0.0, "âŒ"

    emotion_labels = ['Angry', 'Disgust', 'Fear', 'Happy', 'Sad', 'Surprise', 'Neutral']
    emoji_map = {
        "Angry": "ğŸ˜ ", "Disgust": "ğŸ¤¢", "Fear": "ğŸ˜±", "Happy": "ğŸ˜„",
        "Sad": "ğŸ˜¢", "Surprise": "ğŸ˜²", "Neutral": "ğŸ˜"
    }

    gray = cv2.cvtColor(face, cv2.COLOR_BGR2GRAY)
    resized = cv2.resize(gray, (48, 48))
    norm = resized.astype('float32') / 255.0
    input_tensor = np.expand_dims(norm, axis=(0, -1))  # (1, 48, 48, 1)
    preds = model.predict(input_tensor, verbose=0)[0]
    label_idx = np.argmax(preds)
    return emotion_labels[label_idx], preds[label_idx], emoji_map[emotion_labels[label_idx]]

# === Giao diá»‡n chÃ­nh ===
def show_emotion_app():
    st.title("ğŸ§  Nháº­n diá»‡n Cáº£m xÃºc qua KhuÃ´n máº·t")
    st.markdown("Sá»­ dá»¥ng mÃ´ hÃ¬nh há»c sÃ¢u Ä‘á»ƒ phÃ¢n tÃ­ch biá»ƒu cáº£m khuÃ´n máº·t qua áº£nh hoáº·c webcam.")

    model = load_emotion_model()
    mode = st.radio("ğŸ›ï¸ Chá»n cháº¿ Ä‘á»™:", ["ğŸ“ Táº£i áº£nh", "ğŸ“¸ Chá»¥p áº£nh webcam", "ğŸ¥ Webcam real-time"], horizontal=True)

    if mode == "ğŸ“ Táº£i áº£nh":
        uploaded_file = st.file_uploader("ğŸ“¤ Táº£i áº£nh khuÃ´n máº·t", type=["jpg", "png", "jpeg"])
        if uploaded_file:
            img = np.array(Image.open(uploaded_file))
            st.image(img, caption="ğŸ–¼ï¸ áº¢nh Ä‘Ã£ táº£i", use_column_width=True)

            label, conf, emoji = predict_emotion(cv2.cvtColor(img, cv2.COLOR_RGB2BGR), model)
            st.markdown("---")
            st.markdown(f"### ğŸ” Dá»± Ä‘oÃ¡n: **{label}** {emoji}")
            st.markdown(f"#### ğŸ¯ Äá»™ tin cáº­y: `{conf * 100:.2f}%`")

    elif mode == "ğŸ“¸ Chá»¥p áº£nh webcam":
        img_file = st.camera_input("ğŸ“¸ Chá»¥p áº£nh khuÃ´n máº·t")
        if img_file:
            img = np.array(Image.open(img_file))
            st.image(img, caption="ğŸ“· áº¢nh vá»«a chá»¥p", use_container_width=True)

            label, conf, emoji = predict_emotion(cv2.cvtColor(img, cv2.COLOR_RGB2BGR), model)
            st.markdown("---")
            st.markdown(f"### ğŸ” Dá»± Ä‘oÃ¡n: **{label}** {emoji}")
            st.markdown(f"#### ğŸ¯ Äá»™ tin cáº­y: `{conf * 100:.2f}%`")

    elif mode == "ğŸ¥ Webcam real-time":
        run = st.checkbox("â–¶ï¸ Báº¯t Ä‘áº§u phÃ¡t hiá»‡n real-time", key="run_webcam")
        placeholder = st.empty()

        if run:
            st.warning("â¹ï¸ Bá» tick Ä‘á»ƒ dá»«ng webcam.")
            cap = cv2.VideoCapture(0)

            while st.session_state.run_webcam:
                ret, frame = cap.read()
                if not ret:
                    st.error("ğŸš« KhÃ´ng thá»ƒ truy cáº­p webcam.")
                    break

                frame = cv2.flip(frame, 1)
                label, conf, emoji = predict_emotion(frame, model)

                cv2.putText(frame, f"{label} {emoji} ({conf*100:.1f}%)", (10, 30),
                            cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)

                frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
                placeholder.image(frame_rgb, channels="RGB")

            cap.release()
            st.success("âœ… ÄÃ£ dá»«ng webcam.")

