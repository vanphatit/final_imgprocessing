import streamlit as st
import cv2
import numpy as np
import os
from PIL import Image
from ultralytics import YOLO
from ultralytics.utils.plotting import Annotator

def show():
    # === ÄÆ¯á»œNG DáºªN
    BASE_DIR = os.path.dirname(os.path.abspath(__file__))
    MODEL_PATH = os.path.join(BASE_DIR, "fruits_yolov8n.onnx")  # Äá»•i náº¿u cáº§n

    # === LOAD YOLO
    model_yolo = YOLO(MODEL_PATH, task="detect")

    # === LOAD IMAGE
    def load_image(uploaded_file):
        pil_img = Image.open(uploaded_file).convert("RGB")
        img_rgb = np.array(pil_img)
        img_bgr = cv2.cvtColor(img_rgb, cv2.COLOR_RGB2BGR)
        return img_bgr

    # === DETECT FRUIT
    def detect_fruit(imgin):
        imgout = imgin.copy()
        annotator = Annotator(imgout)
        results = model_yolo.predict(imgin, conf=0.5, verbose=False)
        boxes = results[0].boxes.xyxy.cpu()
        clss = results[0].boxes.cls.cpu().tolist()
        confs = results[0].boxes.conf.tolist()
        names = model_yolo.names
        for box, cls, conf in zip(boxes, clss, confs):
            label = f"{names[int(cls)]} {conf:.2f}"
            annotator.box_label(box, label=label, txt_color=(255, 255, 255), color=(0, 153, 255))
        return imgout

    # === UI SETUP
    st.markdown(
        """
        <h1 style='text-align: center; color: #2c3e50;'>
            <img src='https://cdn-icons-png.flaticon.com/512/415/415733.png' width='48' style='vertical-align: middle; margin-bottom: 6px;'/>
            Nháº­n diá»‡n trÃ¡i cÃ¢y báº±ng YOLOv8
        </h1>
        """,
        unsafe_allow_html=True
    )

    mode = st.radio("ğŸ¯ Chá»n cháº¿ Ä‘á»™:", ["áº¢nh tÄ©nh", "Webcam real-time"], horizontal=True)

    # === áº¢NH TÄ¨NH
    if mode == "áº¢nh tÄ©nh":
        uploaded_file = st.file_uploader("ğŸ“‚ Táº£i áº£nh trÃ¡i cÃ¢y", type=["jpg", "jpeg", "png", "bmp"])

        if uploaded_file:
            img_color = load_image(uploaded_file)
            result_img = detect_fruit(img_color)

            col1, col2 = st.columns(2)
            with col1:
                st.markdown("ğŸ–¼ï¸ **áº¢nh Gá»‘c**")
                st.image(img_color, channels="BGR", use_column_width=True)
            with col2:
                st.markdown("ğŸ” **Káº¿t Quáº£ Nháº­n Diá»‡n**")
                st.image(result_img, channels="BGR", use_column_width=True)
        else:
            st.info("ğŸ“¥ HÃ£y chá»n má»™t áº£nh Ä‘á»ƒ báº¯t Ä‘áº§u nháº­n diá»‡n.")

    # === WEBCAM
    else:
        st.markdown("ğŸ“¸ **Báº­t webcam Ä‘á»ƒ nháº­n diá»‡n real-time**")
        run = st.checkbox("ğŸ¥ Báº­t webcam")
        frame_placeholder = st.image([])

        if run:
            cap = cv2.VideoCapture(0)
            while run and cap.isOpened():
                ret, frame = cap.read()
                if not ret:
                    break
                result_frame = detect_fruit(frame)
                frame_placeholder.image(result_frame, channels="BGR")
            cap.release()
