import streamlit as st

def show():
    st.markdown("""
        <style>
            .avatar {
                border-radius: 50%;
                width: 120px;
                height: 120px;
                object-fit: cover;
                border: 3px solid #4F46E5;
            }
            .name {
                font-size: 20px;
                font-weight: bold;
                margin-top: 0.5rem;
            }
            .mssv {
                font-size: 16px;
                color: #666;
            }
            .feature-box {
                background-color: #f3f4f6;
                padding: 16px;
                border-radius: 12px;
                margin-bottom: 12px;
                border-left: 5px solid #4F46E5;
            }
        </style>
    """, unsafe_allow_html=True)

    st.title("ğŸŒ  Image Processing Project: Multi-functional Recognition System")
    st.markdown("### ğŸ‘¨â€ğŸ’» Team Members")

    col1, col2 = st.columns(2)
    with col1:
        st.image("van-phat.jpg", caption="LÃª VÄƒn PhÃ¡t", use_container_width=False, width=120)
        st.markdown("<div class='name'>LÃª VÄƒn PhÃ¡t</div>", unsafe_allow_html=True)
        st.markdown("<div class='mssv'>MSSV: 22110196</div>", unsafe_allow_html=True)
    with col2:
        st.image("thanh-duy.jpg", caption="Huá»³nh Thanh Duy", use_container_width=False, width=120)
        st.markdown("<div class='name'>Huá»³nh Thanh Duy</div>", unsafe_allow_html=True)
        st.markdown("<div class='mssv'>MSSV: 22110118</div>", unsafe_allow_html=True)

    st.markdown("---")
    st.subheader("ğŸ“Œ Project Overview")
    st.markdown("""
        This project is an AI-powered multi-functional system that integrates:
        - Real-time webcam interaction
        - Deep learning + ONNX/TensorFlow models
        - Sign language (ASL), facial, object, fruit, and emotion recognition
        - Traditional image processing and enhancement
    """)

    st.markdown("### âš™ï¸ Main Features")

    features = [
    {
        "icon": "ğŸ‘¤",
        "title": "Face Recognition",
        "desc": """
        <ul>
            <li>ğŸ” Detect faces using <code>YuNet (ONNX)</code></li>
            <li>ğŸ§  Extract embeddings via <code>SFace (ONNX)</code></li>
            <li>ğŸ—‚ï¸ Classify identity using pretrained <code>SVM (joblib)</code></li>
            <li>ğŸ–¥ï¸ Input: Webcam or uploaded photo</li>
        </ul>
        """
    },
    {
        "icon": "ğŸ˜Š",
        "title": "Emotion Detection",
        "desc": """
        <ul>
            <li>ğŸ­ Recognize 7 basic emotions</li>
            <li>ğŸ§  Model: CNN (trained on FER2013)</li>
            <li>ğŸ“ Use MediaPipe FaceMesh for keypoint extraction</li>
            <li>ğŸ“· Real-time webcam input</li>
        </ul>
        """
    },
    {
        "icon": "ğŸ¤Ÿ",
        "title": "ASL Sign Language Detection",
        "desc": """
        <ul>
            <li>âœ‹ Detect hand landmarks using MediaPipe</li>
            <li>ğŸ“¦ Model: MobileNetV2 retrained on our own ASL dataset <code>dataset_retrain</code></li>
            <li>ğŸ§  Predict signs Aâ€“Z except J & Q using CNN</li>
            <li>ğŸ“· Input: Webcam (real-time)</li>
        </ul>
        """
    },
    {
        "icon": "ğŸ“¦",
        "title": "Object Detection",
        "desc": """
        <ul>
            <li>ğŸš€ YOLOv8 pretrained model</li>
            <li>ğŸ¯ Detect objects from COCO classes</li>
            <li>ğŸ–¼ï¸ Input: static image</li>
        </ul>
        """
    },
    {
        "icon": "ğŸ",
        "title": "Fruit Classification",
        "desc": """
        <ul>
            <li>ğŸŒ Identify fruits (apple, banana, orange...)</li>
            <li>ğŸ“¦ Model: Yolov8 </li>
            <li>ğŸ–¼ï¸ Input: uploaded image</li>
        </ul>
        """
    },
    {
        "icon": "ğŸ–¼ï¸",
        "title": "Image Processing",
        "desc": """
        <ul>
            <li>ğŸ“· Functions: grayscale, histogram equalize, blur, sharpen...</li>
            <li>âš™ï¸ Built with OpenCV (Python)</li>
            <li>ğŸ“š Organized by chapter: 3, 4, 5, 9</li>
        </ul>
        """
    },
    {
        "icon": "ğŸ©º",
        "title": "Skin Disease Detection",
        "desc": """
        <ul>
            <li>ğŸ§  Model: <code>ResNet18</code> Ä‘Æ°á»£c huáº¥n luyá»‡n trÃªn táº­p <code>HAM10000</code></li>
            <li>ğŸ“¸ Nháº­n áº£nh qua webcam hoáº·c táº£i lÃªn</li>
            <li>ğŸ” PhÃ¢n loáº¡i 7 loáº¡i bá»‡nh da liá»…u phá»• biáº¿n</li>
            <li>ğŸ“ˆ Dá»± Ä‘oÃ¡n kÃ¨m xÃ¡c suáº¥t vÃ  tÃªn bá»‡nh (Anh + Viá»‡t)</li>
        </ul>
        """
    }
]

    # Render
    for f in features:
        st.markdown(f"""
        <div class='feature-box'>
            <b>{f["icon"]} {f["title"]}</b><br>
            {f["desc"]}
        </div>
        """, unsafe_allow_html=True)

    st.markdown("---")
    st.subheader("ğŸ“ Related Files")
    st.markdown("""
    - `detect_asl.py`, `asl-detector.ipynb` â€“ ASL detection (CNN + Mediapipe)
    - `predict.py` â€“ Face recognition (ONNX + SVM)
    - `emotion.py` â€“ Emotion detection
    - `fruit.py` â€“ Fruit classification
    - `detect_obj.py`, `obj-detector.ipynb` â€“ Object detection using YOLOv8
    - `skin_.py` â€“ Skin disease detection
    - `requirements.txt` â€“ Dependencies
    - `readme.md` â€“ Project documentation
    """)
