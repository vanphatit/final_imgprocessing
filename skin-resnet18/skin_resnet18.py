import streamlit as st
import torch
from torchvision import transforms
from torchvision.models import resnet18
from PIL import Image
import os

# ==== NhÃ£n bá»‡nh: (tiáº¿ng Anh, tiáº¿ng Viá»‡t) ====
label_names = [
    ("Melanocytic nevi (nv)", "Ná»‘t ruá»“i lÃ nh tÃ­nh"),
    ("Melanoma (mel)", "U háº¯c tá»‘ Ã¡c tÃ­nh"),
    ("Benign keratosis-like lesions (bkl)", "Tá»•n thÆ°Æ¡ng sá»«ng hÃ³a lÃ nh tÃ­nh"),
    ("Basal cell carcinoma (bcc)", "Ung thÆ° biá»ƒu mÃ´ táº¿ bÃ o Ä‘Ã¡y"),
    ("Actinic keratoses (akiec)", "DÃ y sá»«ng quang hÃ³a"),
    ("Vascular lesions (vasc)", "Tá»•n thÆ°Æ¡ng máº¡ch mÃ¡u"),
    ("Dermatofibroma (df)", "U xÆ¡ da")
]

# ==== Load model ====
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
MODEL_PATH = os.path.join(BASE_DIR, "skin_resnet18.pth")

model = resnet18(weights=None)
model.fc = torch.nn.Linear(model.fc.in_features, len(label_names))
model.load_state_dict(torch.load(MODEL_PATH, map_location="cpu"))
model.eval()

# ==== Giao diá»‡n chÃ­nh ====
def show_skin():
    st.title("ğŸ©º PhÃ¢n loáº¡i Bá»‡nh Da Liá»…u - HAM10000")
    st.markdown("MÃ´ hÃ¬nh há»c sÃ¢u **ResNet18** Ä‘Æ°á»£c huáº¥n luyá»‡n Ä‘á»ƒ phÃ¢n loáº¡i 7 loáº¡i bá»‡nh da thÆ°á»ng gáº·p.")

    # === Upload áº£nh ===
    uploaded_file = st.file_uploader("ğŸ“¤ Vui lÃ²ng táº£i lÃªn áº£nh vÃ¹ng da cáº§n cháº©n Ä‘oÃ¡n", type=["jpg", "jpeg", "png"])

    # === ThÃ´ng tin mÃ´ hÃ¬nh ===
    with st.expander("ğŸ“Š ThÃ´ng tin mÃ´ hÃ¬nh", expanded=False):
        st.markdown(f"- **TÃªn mÃ´ hÃ¬nh**: `skin_resnet18.pth`")
        st.markdown(f"- **Sá»‘ lá»›p phÃ¢n loáº¡i**: `{len(label_names)}`")
        st.markdown("### ğŸ“š CÃ¡c lá»›p cÃ³ thá»ƒ nháº­n diá»‡n:")
        cols = st.columns(2)
        for i, (eng, viet) in enumerate(label_names):
            with cols[i % 2]:
                st.markdown(f"- **{viet}**  \n  _({eng})_")

    # === Dá»± Ä‘oÃ¡n náº¿u cÃ³ áº£nh ===
    if uploaded_file:
        image = Image.open(uploaded_file).convert("RGB")
        st.image(image, caption="ğŸ–¼ï¸ áº¢nh Ä‘Ã£ táº£i lÃªn", use_column_width=True)

        transform = transforms.Compose([
            transforms.Resize((224, 224)),
            transforms.ToTensor(),
            transforms.Normalize([0.5] * 3, [0.5] * 3)
        ])
        input_tensor = transform(image).unsqueeze(0)

        with torch.no_grad():
            output = model(input_tensor)
            pred = output.argmax(1).item()
            prob = torch.nn.functional.softmax(output, dim=1)[0][pred].item()

        eng, viet = label_names[pred]
        st.success(f"âœ… **Káº¿t quáº£**: {viet}")
        st.caption(f"_({eng})_")
        st.markdown(f"ğŸ“ˆ **Äá»™ tin cáº­y**: `{prob*100:.2f}%`")
    else:
        st.info("ğŸ–¼ï¸ HÃ£y táº£i lÃªn má»™t áº£nh Ä‘á»ƒ báº¯t Ä‘áº§u cháº©n Ä‘oÃ¡n.")

